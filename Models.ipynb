{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation\n",
    "\n",
    "### For missing categorical values imputation have been done by creating a new category \"none\".For numeric values missing values have been imputed by median imputation.\n",
    "### In next steps this imputation would be done by algorithms such as knn and svm and be noted if that leads to improvement in accuarcy of the model.\n",
    "\n",
    "## Data Transformation: \n",
    "\n",
    "### Numeric variables were scaled by minmax scaler as most  of these have different scales.for example budget and num_votes\n",
    "\n",
    "## Scoring\n",
    "\n",
    "### The metric for accuracy has been noted as mean squared error which is one of the most widely used metric for evaluating regression models\n",
    "\n",
    " $$ mse = (\\frac{1}{n})\\sum_{i=1}^{n}(y_{i} - x_{i})^{2} $$\n",
    " \n",
    " ### Lower the MSE better is the model.\n",
    " \n",
    " ## Modelling Techniques\n",
    " \n",
    "### A group of models were evaluated for baselines using sklearn pipeline.The best performing ones were ensemble models hence we evaluated them further by  hyper parameter optimization.The model select was xgboost and it is recommended that the final model of xgboost be deployed as its final parameters reduced MSE by a factor of about 1/6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path=\"movie_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"https://raw.githubusercontent.com/sundeepblue/movie_rating_prediction/master/movie_metadata.csv\"\n",
    "from preprocessing import data_clean\n",
    "\n",
    "data1=data_clean(path)\n",
    "labels=data1.imdb_score.values\n",
    "all_data=pd.concat([data1.drop(columns=[\"genres\"]),data1.genres.str.get_dummies().add_prefix('Part_')],axis=1)\n",
    "all_data=all_data.drop(columns=[\"imdb_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4150, 35)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'imdb_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6cc95a089f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdb_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'imdb_score'"
     ]
    }
   ],
   "source": [
    "all_data.imdb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "numeric_features = all_data._get_numeric_data().columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    \n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "categorical_features=all_data.select_dtypes(exclude=['int',\"float\"]).columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble  import  AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE: linear regression  2288137692706663301120.00 (+/- 9152550770826653204480.00)\n",
      "Model MSE: Lasso 1.11 (+/- 0.26)\n",
      "Model MSE: Ridge 0.79 (+/- 0.21)\n",
      "Model MSE: Decision Trees 1.40 (+/- 0.30)\n",
      "Model MSE: Random Fores 0.70 (+/- 0.20)\n",
      "Model MSE: Ada-Boost 1.01 (+/- 0.33)\n",
      "Model MSE: GBM 0.70 (+/- 0.22)\n",
      "Model MSE: xgboost 0.77 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "regressors = [\n",
    "    (LinearRegression(),\"linear regression \"),\n",
    "    (Lasso(alpha=.5),\"Lasso\"),\n",
    "    (Ridge(alpha=.1),\"Ridge\"),\n",
    "    \n",
    "    (DecisionTreeRegressor(),\"Decision Trees\"),\n",
    "    (RandomForestRegressor(),\"Random Fores\"),\n",
    "    (AdaBoostRegressor(),\"Ada-Boost\"),\n",
    "    (GradientBoostingRegressor(),\"GBM\"),\n",
    "    (XGBRegressor(),\"xgboost\")\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "def MSE(y_true,y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    #print ('MSE: %2.3f' % mse)\n",
    "    return mse\n",
    "mse=make_scorer(MSE)\n",
    "\n",
    "\n",
    "for r,v in regressors :\n",
    "    \n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', r)])\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores = cross_val_score(clf,all_data, labels, cv=5,scoring=mse)\n",
    "    \n",
    "    print(\"Model MSE:\"+ \" \" + str(v)+\" \"+\"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('scaler',\n",
       "                                                                                          MinMaxScaler(copy=True,\n",
       "                                                                                                       feature_range=(0,\n",
       "                                                                                                                      1)))],\n",
       "                                                                                  verbose=False),\n",
       "                                                                         Index(['actor_1_facebook_likes', 'actor_2_facebook...\n",
       "                                                     scale_pos_weight=None,\n",
       "                                                     subsample=None,\n",
       "                                                     tree_method=None,\n",
       "                                                     validate_parameters=False,\n",
       "                                                     verbosity=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'xgbrg__learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'xgbrg__max_depth': range(2, 10),\n",
       "                         'xgbrg__n_estimators': range(60, 220, 40)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(MSE), verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_pipeline=Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('xgbrg', XGBRegressor())])\n",
    "parameters = {\n",
    "    'xgbrg__max_depth': range (2, 10, 1),\n",
    "    'xgbrg__n_estimators': range(60, 220, 40),\n",
    "    'xgbrg__learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "# fit_params = {\"xgbrg__eval_set\": [(X_test, y_test)], \n",
    "#               \"xgbrg__early_stopping_rounds\": 10, \n",
    "#               \"xgbrg__verbose\": False} \n",
    "\n",
    "searchCV = GridSearchCV(xgb_pipeline, cv=5, param_grid=parameters,scoring=mse)\n",
    "searchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.672789338328254"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbrg__learning_rate': 0.01,\n",
       " 'xgbrg__max_depth': 9,\n",
       " 'xgbrg__n_estimators': 60}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchCV.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
